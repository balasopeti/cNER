{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e66f6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all imports required\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "from numpy import array\n",
    "from numpy.random import seed\n",
    "from keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Model, Input\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5f653f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to import data and return it in a dataframe\n",
    "\n",
    "def getRawData(path):\n",
    "    return pd.read_excel(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad2b546a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to define token to id and id to token\n",
    "def get_dict_map(data, token_or_tag):\n",
    "    tok2idx = {}\n",
    "    idx2tok = {}\n",
    "    \n",
    "    if token_or_tag == 'token':\n",
    "        vocab = list(set(data['Text'].to_list()))\n",
    "    else:\n",
    "        vocab = list(set(data['Label'].to_list()))\n",
    "    \n",
    "    idx2tok = {idx:tok for  idx, tok in enumerate(vocab)}\n",
    "    tok2idx = {tok:idx for  idx, tok in enumerate(vocab)}\n",
    "    return tok2idx, idx2tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "101e5fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get extra columns of token to id representation for text and label\n",
    "def getDataTagged(data,tok2idx,tag2idx):\n",
    "    data['Word_idx'] = data['Text'].map(token2idx)\n",
    "    data['Tag_idx'] = data['Label'].map(tag2idx)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d5177dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGroupedData(data):\n",
    "    data_fillna = data.fillna(method='ffill', axis=0)\n",
    "    for i in range(len(data)):\n",
    "        print(i)\n",
    "        data_group = data_fillna.groupby([\"Sentence\"],as_index=False)['Text', 'POS', 'Label', 'Word_idx', 'Tag_idx'].agg(lambda x: list(x))\n",
    "    return data_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b88e3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pad_train_test_val(data_group, data):\n",
    "    n_token = len(list(set(data['Text'].to_list())))\n",
    "    n_tag = len(list(set(data['Label'].to_list())))   \n",
    "    tokens = data_group['Word_idx'].tolist()\n",
    "    maxlen = max([len(s) for s in tokens])\n",
    "    pad_tokens = pad_sequences(tokens, maxlen=maxlen, dtype='int32', padding='post', value= n_token - 1)\n",
    "    tags = data_group['Tag_idx'].tolist()\n",
    "    pad_tags = pad_sequences(tags, maxlen=maxlen, dtype='int32', padding='post')\n",
    "    n_tags = len(tag2idx)\n",
    "    pad_tags = [to_categorical(i, num_classes=n_tags) for i in pad_tags]\n",
    "    tokens_, test_tokens, tags_, test_tags = train_test_split(pad_tokens, pad_tags, test_size=0.1, train_size=0.9, random_state=2020)\n",
    "    train_tokens, val_tokens, train_tags, val_tags = train_test_split(tokens_,tags_,test_size = 0.25,train_size =0.75, random_state=2020)\n",
    "    print(\n",
    "        'train_tokens length:', len(train_tokens),\n",
    "        '\\ntest_tokens length:', len(test_tokens),\n",
    "        '\\ntest_tags:', len(test_tags),\n",
    "        '\\nval_tokens:', len(val_tokens),\n",
    "        '\\nval_tags:', len(val_tags),\n",
    "    )\n",
    "    return train_tokens, val_tokens, test_tokens, train_tags, val_tags, test_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86ef0961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bilstm_lstm_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add Embedding layer\n",
    "    model.add(Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length))\n",
    "\n",
    "    # Add bidirectional LSTM\n",
    "    model.add(Bidirectional(LSTM(units=output_dim, return_sequences=True, dropout=0.2, recurrent_dropout=0.2), merge_mode = 'concat'))\n",
    "\n",
    "    # Add LSTM\n",
    "    model.add(LSTM(units=output_dim, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n",
    "\n",
    "    # Add timeDistributed Layer\n",
    "    model.add(TimeDistributed(Dense(n_tags, activation=\"softmax\")))\n",
    "\n",
    "    #Optimiser \n",
    "    # adam = k.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4339273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y, model):\n",
    "    loss = list()\n",
    "    for i in range(25):\n",
    "        # fit model for one epoch on this sequence\n",
    "        hist = model.fit(X, y, batch_size=1000, verbose=1, epochs=1, validation_split=0.2)\n",
    "        loss.append(hist.history['loss'][0])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "413d5f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModel(model_bilstm_lstm,save_model):\n",
    "    #model.save(model_bilstm_lstm)\n",
    "    tf.saved_model.save(model_bilstm_lstm,save_model )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dfa23e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    nlp = spacy.load('bilstm_1_dense')\n",
    "    text = \"Dr. Ferris's research is focused on cellular immune mechanisms of natural killer (NK) cell, dendritic cells (DC) and T lymphocyte activation against head and neck cancer (HNC) tumor antigens. In addition his group pioneered studies demonstrating innate and adaptive immune responses induced by EGFR-specific mAb, cetuximab in cancer patients.\"\n",
    "    doc = nlp(text)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c095961",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=getRawData('improved_data.xlsx')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29446645",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#data=getRawData('improved_data.xlsx')\n",
    "token2idx, idx2token = get_dict_map(data, 'token')\n",
    "tag2idx, idx2tag = get_dict_map(data, 'tag')\n",
    "data_idx=getDataTagged(data,token2idx,tag2idx)\n",
    "data_group=getGroupedData(data)\n",
    "train_tokens, val_tokens, test_tokens, train_tags, val_tags, test_tags = get_pad_train_test_val(data_group, data)\n",
    "input_dim = len(list(set(data['Text'].to_list())))+1\n",
    "output_dim = 64\n",
    "input_length = max([len(s) for s in data_group['Word_idx'].tolist()])\n",
    "n_tags = len(tag2idx)\n",
    "results = pd.DataFrame()\n",
    "model_bilstm_lstm = get_bilstm_lstm_model()\n",
    "#plot_model(model_bilstm_lstm)\n",
    "results['with_add_lstm'] = train_model(train_tokens, np.array(train_tags), model_bilstm_lstm)\n",
    "save_model=saveModel(model_bilstm_lstm,save_model)\n",
    "output=save_model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a939c84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0c6610",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Attachments",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
