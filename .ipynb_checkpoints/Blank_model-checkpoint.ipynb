{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e1be088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import spacy\n",
    "from spacy.tokens import Doc\n",
    "from spacy.pipeline import EntityRecognizer\n",
    "from thinc.layers import PyTorchWrapper\n",
    "import torch\n",
    "from spacy.tokens import Span\n",
    "from spacy.language import Language\n",
    "from spacy.tokens import Token\n",
    "from spacy import displacy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, TimeDistributed, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "935f2ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Excel sheet\n",
    "file_path = \"MasterList (3).xlsx\"\n",
    "data = pd.read_excel(file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79ed6486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the text and the names\n",
    "texts = data['Text'].tolist()\n",
    "names = data['Name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bc5f64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3fab7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the texts and the names\n",
    "text_tokenizer = Tokenizer(char_level=True)\n",
    "text_tokenizer.fit_on_texts(texts)\n",
    "text_sequences = text_tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "name_tokenizer = Tokenizer(char_level=True)\n",
    "name_tokenizer.fit_on_texts(names)\n",
    "name_sequences = name_tokenizer.texts_to_sequences(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5ae54d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pad the sequences\n",
    "max_length = max([len(seq) for seq in text_sequences])\n",
    "text_sequences_padded = pad_sequences(text_sequences, maxlen=max_length, padding='post')\n",
    "name_sequences_padded = pad_sequences(name_sequences, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ea6af29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the names to one-hot encoding\n",
    "name_sequences_onehot = [to_categorical(seq, num_classes=len(name_tokenizer.word_index) + 1) for seq in name_sequences_padded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3badcce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "train_texts, val_texts, train_names, val_names = train_test_split(text_sequences_padded, np.array(name_sequences_onehot), test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2ad9899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "input_dim = len(text_tokenizer.word_index) + 1\n",
    "output_dim = len(name_tokenizer.word_index) + 1\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(max_length,)),\n",
    "    Embedding(input_dim=input_dim, output_dim=32, input_length=max_length),\n",
    "    Bidirectional(LSTM(units=32, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)),\n",
    "    LSTM(units=32, return_sequences=True, dropout=0.5, recurrent_dropout=0.5),\n",
    "    TimeDistributed(Dense(output_dim, activation=\"softmax\"))\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "024f67d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5/5 [==============================] - 377s 75s/step - loss: 3.3156 - accuracy: 0.7145 - val_loss: 3.2226 - val_accuracy: 0.9969\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 360s 75s/step - loss: 3.1111 - accuracy: 0.9968 - val_loss: 2.8723 - val_accuracy: 0.9969\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 339s 68s/step - loss: 2.6093 - accuracy: 0.9968 - val_loss: 2.0730 - val_accuracy: 0.9969\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 340s 71s/step - loss: 1.7636 - accuracy: 0.9968 - val_loss: 1.1431 - val_accuracy: 0.9969\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 313s 64s/step - loss: 0.9212 - accuracy: 0.9968 - val_loss: 0.5197 - val_accuracy: 0.9969\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_texts, train_names, epochs=5, batch_size=16, validation_data=(val_texts, val_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fddafb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Embedding' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4820\\3453345134.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Convert Keras model to PyTorch model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtorch_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mPyTorchWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Create a custom spaCy component\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mKerasEntityRecognizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEntityRecognizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4820\\3453345134.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Convert Keras model to PyTorch model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtorch_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mPyTorchWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Create a custom spaCy component\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mKerasEntityRecognizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEntityRecognizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\layers\\pytorchwrapper.py\u001b[0m in \u001b[0;36mPyTorchWrapper\u001b[1;34m(pytorch_model, convert_inputs, convert_outputs)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mforward\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"convert_inputs\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mconvert_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"convert_outputs\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mconvert_outputs\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[0mshims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mPyTorchShim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpytorch_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m         \u001b[0mdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"nI\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"nO\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\shims\\pytorch.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model, config, optimizer, mixed_precision, grad_scaler, device, serialize_model, deserialize_model)\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_torch_default_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgrad_scaler\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Embedding' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "# Convert Keras model to PyTorch model\n",
    "torch_model = torch.nn.Sequential(*[PyTorchWrapper(layer) for layer in model.layers])\n",
    "\n",
    "# Create a custom spaCy component\n",
    "class KerasEntityRecognizer(EntityRecognizer):\n",
    "    def predict(self, docs):\n",
    "        X = [doc.tensor for doc in docs]\n",
    "        X_padded = pad_sequences(X, maxlen=max_length, padding='post')\n",
    "        y_pred = self.model(torch.tensor(X_padded, dtype=torch.float32))\n",
    "        return y_pred.detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "017d548a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Language.component(\"keras_entity_recognizer\")\n",
    "def keras_entity_recognizer(doc):\n",
    "    # Convert the document text into input for the model\n",
    "    text_sequence = text_tokenizer.texts_to_sequences([doc.text])\n",
    "    text_sequence_padded = pad_sequences(text_sequence, maxlen=max_length, padding='post')\n",
    "\n",
    "    # Get the model predictions\n",
    "    predictions = model.predict(text_sequence_padded)[0]\n",
    "\n",
    "    # Extract the name from the predictions\n",
    "    name_indices = np.argmax(predictions, axis=-1)\n",
    "    name_tokens = [name_tokenizer.index_word[idx] if idx > 0 else '' for idx in name_indices]\n",
    "\n",
    "    # Assign the name tokens to the doc\n",
    "    for i, token in enumerate(doc):\n",
    "        if name_tokens[i]:\n",
    "            token._.name = name_tokens[i]\n",
    "        else:\n",
    "            token._.name = \"\"\n",
    "\n",
    "    # Add entities to the doc\n",
    "    for token in doc:\n",
    "        if token._.name:\n",
    "            doc.ents += (Span(doc, token.i, token.i + 1, label='PERSON'),)\n",
    "\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92ac6b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 12s 12s/step\n",
      "Entities found: [('Sharath Chandra Mouli', 'PERSON'), ('the Krishna Institute of Medical Sciences', 'ORG'), ('Secunderabad', 'GPE'), ('Telangana', 'GPE'), ('India', 'GPE'), ('Mouli', 'PERSON'), ('the Rajiv Gandhi University of Health Sciences', 'ORG'), ('Bangalore', 'GPE'), ('India', 'GPE'), (\"Nizam's Institute of Medical Sciences\", 'ORG'), ('Hyderabad', 'GPE'), ('India', 'GPE'), ('several years', 'DATE'), ('Gastroenterology', 'ORG'), ('India', 'GPE'), ('Mouli', 'PERSON'), ('EUS', 'ORG'), ('ERCP', 'ORG'), ('Mouli', 'PERSON'), ('Gastroenterology', 'ORG')]\n"
     ]
    }
   ],
   "source": [
    "# Register the custom attribute\n",
    "Token.set_extension('name', default='')\n",
    "\n",
    "# Load a spaCy model and add the custom component\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe(\"keras_entity_recognizer\")\n",
    "\n",
    "# Process a text using the spaCy pipeline\n",
    "text = \" Dr. Sharath Chandra Mouli is a medical doctor who specializes in the field of Gastroenterology. He is associated with the Krishna Institute of Medical Sciences (KIMS) Hospital in Secunderabad, Telangana, India.Dr. Mouli completed his MBBS degree from the Rajiv Gandhi University of Health Sciences in Bangalore, India, and then went on to pursue a Doctorate of Medicine (DM) in Gastroenterology from the Nizam's Institute of Medical Sciences in Hyderabad, India. He has several years of experience in the field of Gastroenterology and has worked at various prestigious institutions across India.Dr. Mouli's areas of expertise include the diagnosis and treatment of various gastrointestinal disorders such as inflammatory bowel disease, liver diseases, pancreatic disorders, and motility disorders. He is also trained in performing advanced endoscopic procedures such as endoscopic ultrasound (EUS), endoscopic retrograde cholangiopancreatography (ERCP), and endoscopic mucosal resection (EMR).Apart from his clinical work, Dr. Mouli is also involved in research activities in the field of Gastroenterology and has published several articles in peer-reviewed medical journals.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "# Print the extracted entities\n",
    "print(\"Entities found:\", [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d98de791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> Dr. \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sharath Chandra Mouli\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is a medical doctor who specializes in the field of Gastroenterology. He is associated with the Krishna Institute of Medical Sciences (KIMS) Hospital in Secunderabad, Telangana, India.Dr. \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mouli\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " completed his MBBS degree from the Rajiv Gandhi University of Health Sciences in Bangalore, India, and then went on to pursue a Doctorate of Medicine (DM) in Gastroenterology from the Nizam's Institute of Medical Sciences in Hyderabad, India. He has several years of experience in the field of Gastroenterology and has worked at various prestigious institutions across India.Dr. \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mouli\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       "'s areas of expertise include the diagnosis and treatment of various gastrointestinal disorders such as inflammatory bowel disease, liver diseases, pancreatic disorders, and motility disorders. He is also trained in performing advanced endoscopic procedures such as endoscopic ultrasound (EUS), endoscopic retrograde cholangiopancreatography (ERCP), and endoscopic mucosal resection (EMR).Apart from his clinical work, Dr. \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mouli\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is also involved in research activities in the field of Gastroenterology and has published several articles in peer-reviewed medical journals.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the named entities using displaCy\n",
    "displacy.render(doc, style='ent', options={'ents': ['PERSON']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2521e993",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
