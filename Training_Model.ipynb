{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a037bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, TimeDistributed, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed8248be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ada39238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt the user to enter the file path\n",
    "file_path = \"MasterList (3).xlsx\"\n",
    "df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92837246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Name</th>\n",
       "      <th>Interest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dr. Yue Cao is a highly respected radiologist ...</td>\n",
       "      <td>Yue Cao</td>\n",
       "      <td>tumor ;; tissue therapy;;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dr. Bensheng Qiu is a renowned radiologist kno...</td>\n",
       "      <td>Bensheng Qiu</td>\n",
       "      <td>radiology;;cancers;;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dr. Robert Fleck began his academic journey wi...</td>\n",
       "      <td>Robert Fleck J</td>\n",
       "      <td>cancer ;;diagnosis;;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dr. Holden Wu is a renowned radiologist who ha...</td>\n",
       "      <td>Holden Wu</td>\n",
       "      <td>novel imaging modalities;;cardiac magnetic res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dr. William Hyslop is a renowned radiologist w...</td>\n",
       "      <td>William Hyslop</td>\n",
       "      <td>MRI;;PET;;CT;;radiology;;diagnosis;;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Dr. Claude Sirlin is a highly accomplished rad...</td>\n",
       "      <td>Claude Sirlin</td>\n",
       "      <td>MRI imaging;;liver cancer;; liver disease;;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Dr. Martin Prince is a renowned radiologist wh...</td>\n",
       "      <td>Martin Prince</td>\n",
       "      <td>gadolinium-enhanced MR Angiography;; Investig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Dr. Scott Reeder is a renowned radiologist kno...</td>\n",
       "      <td>Scott Reeder</td>\n",
       "      <td>abdominal adiposity;; liver fat;; liver iron;;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Dr. David Bluemke is a renowned radiologist kn...</td>\n",
       "      <td>David Bluemke</td>\n",
       "      <td>diagnosis;;cardiovascular diseases;; coronary...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Dr. David Nascene is a renowned radiologist kn...</td>\n",
       "      <td>David Nascene</td>\n",
       "      <td>MRI;;CT;;diagnosing;; cancer;; cardiovascular...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text            Name  \\\n",
       "0    Dr. Yue Cao is a highly respected radiologist ...         Yue Cao   \n",
       "1    Dr. Bensheng Qiu is a renowned radiologist kno...    Bensheng Qiu   \n",
       "2    Dr. Robert Fleck began his academic journey wi...  Robert Fleck J   \n",
       "3    Dr. Holden Wu is a renowned radiologist who ha...       Holden Wu   \n",
       "4    Dr. William Hyslop is a renowned radiologist w...  William Hyslop   \n",
       "..                                                 ...             ...   \n",
       "96   Dr. Claude Sirlin is a highly accomplished rad...   Claude Sirlin   \n",
       "97   Dr. Martin Prince is a renowned radiologist wh...   Martin Prince   \n",
       "98   Dr. Scott Reeder is a renowned radiologist kno...    Scott Reeder   \n",
       "99   Dr. David Bluemke is a renowned radiologist kn...   David Bluemke   \n",
       "100  Dr. David Nascene is a renowned radiologist kn...   David Nascene   \n",
       "\n",
       "                                              Interest  \n",
       "0                            tumor ;; tissue therapy;;  \n",
       "1                                 radiology;;cancers;;  \n",
       "2                                 cancer ;;diagnosis;;  \n",
       "3    novel imaging modalities;;cardiac magnetic res...  \n",
       "4                MRI;;PET;;CT;;radiology;;diagnosis;;   \n",
       "..                                                 ...  \n",
       "96         MRI imaging;;liver cancer;; liver disease;;  \n",
       "97    gadolinium-enhanced MR Angiography;; Investig...  \n",
       "98   abdominal adiposity;; liver fat;; liver iron;;...  \n",
       "99    diagnosis;;cardiovascular diseases;; coronary...  \n",
       "100   MRI;;CT;;diagnosing;; cancer;; cardiovascular...  \n",
       "\n",
       "[101 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "966bf8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the texts and the names\n",
    "texts = df['Text'].tolist()\n",
    "names = df['Name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ac43dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tokenizer for the texts and the names\n",
    "tokenizer = Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(texts + names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977768cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the texts and the names to sequences of integers\n",
    "text_sequences = tokenizer.texts_to_sequences(texts)\n",
    "name_sequences = tokenizer.texts_to_sequences(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27f8ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the sequences with zeros to the maximum sequence length\n",
    "max_length = max([len(seq) for seq in text_sequences + name_sequences])\n",
    "text_sequences_padded = pad_sequences(text_sequences, maxlen=max_length, padding='post')\n",
    "name_sequences_padded = pad_sequences(name_sequences, maxlen=max_length, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409a9a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the name sequences to one-hot encoding\n",
    "name_sequences_onehot = to_categorical(name_sequences_padded, num_classes=len(tokenizer.word_index) + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca8eef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, validation, and test sets\n",
    "train_texts, test_texts, train_names, test_names = train_test_split(text_sequences_padded, name_sequences_onehot, test_size=0.2, random_state=42)\n",
    "train_texts, val_texts, train_names, val_names = train_test_split(train_texts, train_names, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b378a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create the Keras model\n",
    "def create_model(input_dim, output_dim, max_length):\n",
    "    model = Sequential([\n",
    "        Input(shape=(max_length,)),\n",
    "        Embedding(input_dim=input_dim, output_dim=32, input_length=max_length),\n",
    "        Bidirectional(LSTM(units=32, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)),\n",
    "        LSTM(units=32, return_sequences=True, dropout=0.5, recurrent_dropout=0.5),\n",
    "        TimeDistributed(Dense(output_dim, activation=\"softmax\"))\n",
    "    ])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487b746c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the input and output dimensions\n",
    "input_dim = len(tokenizer.word_index) + 1\n",
    "output_dim = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Create the Keras model\n",
    "model = create_model(input_dim, output_dim, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfc3ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the training set and validate on the validation set\n",
    "history = model.fit(train_texts, train_names, epochs=5, batch_size=16, validation_data=(val_texts, val_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a579f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(test_texts, test_names)\n",
    "print(\"Test loss:\", loss)\n",
    "print(\"Test accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9a74ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_named_entities(text, model, tokenizer):\n",
    "    # Tokenize the text\n",
    "    text_sequence = tokenizer.texts_to_sequences([text])\n",
    "    text_sequence_padded = pad_sequences(text_sequence, maxlen=max_length, padding='post')\n",
    "\n",
    "    # Make predictions using the model\n",
    "    predictions = model.predict(text_sequence_padded)[0]\n",
    "\n",
    "    # Extract the named entities from the predictions\n",
    "    name_indices = np.argmax(predictions, axis=-1)\n",
    "    name_tokens = [tokenizer.index_word[idx] if idx > 0 else '' for idx in name_indices]\n",
    "\n",
    "    # Create a list of spans representing the named entities\n",
    "    spans = []\n",
    "    start = None\n",
    "    for i, token in enumerate(name_tokens):\n",
    "        if token and not start:\n",
    "            start = i\n",
    "        elif not token and start:\n",
    "            end = i\n",
    "            spans.append((start, end))\n",
    "            start = None\n",
    "    if start:\n",
    "        end = len(name_tokens)\n",
    "        spans.append((start, end))\n",
    "\n",
    "    # Create a list of spaCy entities from the spans\n",
    "    entities = []\n",
    "    for start, end in spans:\n",
    "        if 'PERSON' in predictions[start:end]:\n",
    "            entities.append(spacy.tokens.Span(doc, start, end, label='PERSON'))\n",
    "\n",
    "    return entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a22a37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a function to add the named entities to a spaCy doc\n",
    "def add_named_entities(doc, entities):\n",
    "    for ent in entities:\n",
    "        doc.ents += (ent,)\n",
    "    return doc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189b51b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# Get a reference to the named entity recognition component\n",
    "ner = nlp.get_pipe(\"ner\")\n",
    "# Process a text and extract the named entities\n",
    "text = \" Dr. Sharath Chandra Mouli is a medical doctor who specializes in the field of Gastroenterology. He is associated with the Krishna Institute of Medical Sciences (KIMS) Hospital in Secunderabad, Telangana, India.Dr. Mouli completed his MBBS degree from the Rajiv Gandhi University of Health Sciences in Bangalore, India, and then went on to pursue a Doctorate of Medicine (DM) in Gastroenterology from the Nizam's Institute of Medical Sciences in Hyderabad, India. He has several years of experience in the field of Gastroenterology and has worked at various prestigious institutions across India.Dr. Mouli's areas of expertise include the diagnosis and treatment of various gastrointestinal disorders such as inflammatory bowel disease, liver diseases, pancreatic disorders, and motility disorders. He is also trained in performing advanced endoscopic procedures such as endoscopic ultrasound (EUS), endoscopic retrograde cholangiopancreatography (ERCP), and endoscopic mucosal resection (EMR).Apart from his clinical work, Dr. Mouli is also involved in research activities in the field of Gastroenterology and has published several articles in peer-reviewed medical journals.\"\n",
    "doc = nlp(text)\n",
    "entities = extract_named_entities(text, model, tokenizer)\n",
    "person_entities = [ent for ent in entities if ent.label_ == 'PERSON']\n",
    "doc = add_named_entities(doc, person_entities)\n",
    "#doc = add_named_entities(doc, entities)\n",
    "\n",
    "# Print the named entities\n",
    "print(\"Named entities found:\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e2dc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualize the named entities using displaCy\n",
    "spacy.displacy.render(doc, style='ent')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433e634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a function to extract the named entities from a text using the trained model\n",
    "def extract_named_entities(text, model, tokenizer):\n",
    "    # Tokenize the text\n",
    "    text_sequence = tokenizer.texts_to_sequences([text])\n",
    "    text_sequence_padded = pad_sequences(text_sequence, maxlen=max_length, padding='post')\n",
    "\n",
    "    # Make predictions using the model\n",
    "    predictions = model.predict(text_sequence_padded)[0]\n",
    "\n",
    "    # Extract the named entities from the predictions\n",
    "    name_indices = np.argmax(predictions, axis=-1)\n",
    "    name_tokens = [tokenizer.index_word[idx] if idx > 0 else '' for idx in name_indices]\n",
    "\n",
    "    # Create a list of spans representing the named entities\n",
    "    spans = []\n",
    "    start = None\n",
    "    for i, token in enumerate(name_tokens):\n",
    "        if token and not start:\n",
    "            start = i\n",
    "        elif not token and start:\n",
    "            end = i\n",
    "            label = 'PERSON'\n",
    "            spans.append((start, end, label))\n",
    "            start = None\n",
    "    if start:\n",
    "        end = len(name_tokens)\n",
    "        label = 'PERSON'\n",
    "        spans.append((start, end, label))\n",
    "\n",
    "    # Create a list of spaCy entities from the spans\n",
    "    entities = []\n",
    "    for start, end, label in spans:\n",
    "        entities.append(spacy.tokens.Span(doc, start, end, label=label))\n",
    "\n",
    "    return entities\n",
    "\n",
    "# Define a function to add the named entities to a spaCy doc\n",
    "def add_named_entities(doc, entities):\n",
    "    for ent in entities:\n",
    "        doc.ents += (ent,)\n",
    "    return doc\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
