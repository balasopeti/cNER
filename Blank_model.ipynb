{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4ad7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow-mkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7fd9711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import spacy\n",
    "from spacy.tokens import Doc\n",
    "from spacy.pipeline import EntityRecognizer\n",
    "from thinc.layers import PyTorchWrapper\n",
    "import torch\n",
    "from spacy.tokens import Span\n",
    "from spacy.language import Language\n",
    "from spacy.tokens import Token\n",
    "from spacy import displacy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, TimeDistributed, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4be01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow-mkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580b1960",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt\n",
    "#!pip install package-name\n",
    "#print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a53069a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Excel sheet\n",
    "file_path = \"MasterList (3).xlsx\"\n",
    "df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f0c3be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Name</th>\n",
       "      <th>Interest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dr. Yue Cao is a highly respected radiologist ...</td>\n",
       "      <td>Yue Cao</td>\n",
       "      <td>tumor ;; tissue therapy;;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dr. Bensheng Qiu is a renowned radiologist kno...</td>\n",
       "      <td>Bensheng Qiu</td>\n",
       "      <td>radiology;;cancers;;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dr. Robert Fleck began his academic journey wi...</td>\n",
       "      <td>Robert Fleck J</td>\n",
       "      <td>cancer ;;diagnosis;;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dr. Holden Wu is a renowned radiologist who ha...</td>\n",
       "      <td>Holden Wu</td>\n",
       "      <td>novel imaging modalities;;cardiac magnetic res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dr. William Hyslop is a renowned radiologist w...</td>\n",
       "      <td>William Hyslop</td>\n",
       "      <td>MRI;;PET;;CT;;radiology;;diagnosis;;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Dr. Claude Sirlin is a highly accomplished rad...</td>\n",
       "      <td>Claude Sirlin</td>\n",
       "      <td>MRI imaging;;liver cancer;; liver disease;;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Dr. Martin Prince is a renowned radiologist wh...</td>\n",
       "      <td>Martin Prince</td>\n",
       "      <td>gadolinium-enhanced MR Angiography;; Investig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Dr. Scott Reeder is a renowned radiologist kno...</td>\n",
       "      <td>Scott Reeder</td>\n",
       "      <td>abdominal adiposity;; liver fat;; liver iron;;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Dr. David Bluemke is a renowned radiologist kn...</td>\n",
       "      <td>David Bluemke</td>\n",
       "      <td>diagnosis;;cardiovascular diseases;; coronary...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Dr. David Nascene is a renowned radiologist kn...</td>\n",
       "      <td>David Nascene</td>\n",
       "      <td>MRI;;CT;;diagnosing;; cancer;; cardiovascular...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text            Name  \\\n",
       "0    Dr. Yue Cao is a highly respected radiologist ...         Yue Cao   \n",
       "1    Dr. Bensheng Qiu is a renowned radiologist kno...    Bensheng Qiu   \n",
       "2    Dr. Robert Fleck began his academic journey wi...  Robert Fleck J   \n",
       "3    Dr. Holden Wu is a renowned radiologist who ha...       Holden Wu   \n",
       "4    Dr. William Hyslop is a renowned radiologist w...  William Hyslop   \n",
       "..                                                 ...             ...   \n",
       "96   Dr. Claude Sirlin is a highly accomplished rad...   Claude Sirlin   \n",
       "97   Dr. Martin Prince is a renowned radiologist wh...   Martin Prince   \n",
       "98   Dr. Scott Reeder is a renowned radiologist kno...    Scott Reeder   \n",
       "99   Dr. David Bluemke is a renowned radiologist kn...   David Bluemke   \n",
       "100  Dr. David Nascene is a renowned radiologist kn...   David Nascene   \n",
       "\n",
       "                                              Interest  \n",
       "0                            tumor ;; tissue therapy;;  \n",
       "1                                 radiology;;cancers;;  \n",
       "2                                 cancer ;;diagnosis;;  \n",
       "3    novel imaging modalities;;cardiac magnetic res...  \n",
       "4                MRI;;PET;;CT;;radiology;;diagnosis;;   \n",
       "..                                                 ...  \n",
       "96         MRI imaging;;liver cancer;; liver disease;;  \n",
       "97    gadolinium-enhanced MR Angiography;; Investig...  \n",
       "98   abdominal adiposity;; liver fat;; liver iron;;...  \n",
       "99    diagnosis;;cardiovascular diseases;; coronary...  \n",
       "100   MRI;;CT;;diagnosing;; cancer;; cardiovascular...  \n",
       "\n",
       "[101 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79ed6486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the text and the names\n",
    "texts = df['Text'].tolist()\n",
    "names = df['Name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3fab7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the texts and the names\n",
    "text_tokenizer = Tokenizer(char_level=True)\n",
    "text_tokenizer.fit_on_texts(texts)\n",
    "text_sequences = text_tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "name_tokenizer = Tokenizer(char_level=True)\n",
    "name_tokenizer.fit_on_texts(names)\n",
    "name_sequences = name_tokenizer.texts_to_sequences(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5ae54d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pad the sequences\n",
    "max_length = max([len(seq) for seq in text_sequences])\n",
    "text_sequences_padded = pad_sequences(text_sequences, maxlen=max_length, padding='post')\n",
    "name_sequences_padded = pad_sequences(name_sequences, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ea6af29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the names to one-hot encoding\n",
    "name_sequences_onehot = [to_categorical(seq, num_classes=len(name_tokenizer.word_index) + 1) for seq in name_sequences_padded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3badcce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "train_texts, val_texts, train_names, val_names = train_test_split(text_sequences_padded, np.array(name_sequences_onehot), test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2ad9899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "input_dim = len(text_tokenizer.word_index) + 1\n",
    "#output_dim = len(name_tokenizer.word_index) + 1\n",
    "output_dim = len(text_tokenizer.word_index) + 1\n",
    "model = Sequential([\n",
    "    Input(shape=(max_length,)),\n",
    "    Embedding(input_dim=input_dim, output_dim=32, input_length=max_length),\n",
    "    Bidirectional(LSTM(units=32, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)),\n",
    "    LSTM(units=32, return_sequences=True, dropout=0.5, recurrent_dropout=0.5),\n",
    "    TimeDistributed(Dense(output_dim, activation=\"softmax\"))\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dea7764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, input_dim, max_length, output_dim):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, 64, max_norm=max_length)\n",
    "        self.bi_lstm = nn.LSTM(64, 64, batch_first=True, bidirectional=True, dropout=0.2)\n",
    "        self.lstm = nn.LSTM(128, 64, batch_first=True, dropout=0.5)\n",
    "        self.time_distributed = nn.Linear(64, output_dim)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.bi_lstm(x)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.time_distributed(x)\n",
    "        #x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "input_dim = len(text_tokenizer.word_index) + 1 # Set the input dimension\n",
    "max_length = len(text_tokenizer.word_index) + 1  # Set the maximum sequence length\n",
    "output_dim = len(text_tokenizer.word_index) + 1 # Set the output dimension\n",
    "model = MyModel(input_dim, max_length, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47447d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiru\\AppData\\Local\\Temp\\ipykernel_27680\\2767264696.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_texts = torch.tensor(train_texts, dtype=torch.long)\n",
      "C:\\Users\\thiru\\AppData\\Local\\Temp\\ipykernel_27680\\2767264696.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_names = torch.tensor(train_names, dtype=torch.long)\n",
      "C:\\Users\\thiru\\AppData\\Local\\Temp\\ipykernel_27680\\2767264696.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_texts = torch.tensor(val_texts, dtype=torch.long)\n",
      "C:\\Users\\thiru\\AppData\\Local\\Temp\\ipykernel_27680\\2767264696.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_names = torch.tensor(val_names, dtype=torch.long)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (66832) to match target batch_size (1938128).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27680\\2767264696.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1173\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1174\u001b[1;33m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[0;32m   1175\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m                                label_smoothing=self.label_smoothing)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3024\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3025\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3026\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3027\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3028\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected input batch_size (66832) to match target batch_size (1938128)."
     ]
    }
   ],
   "source": [
    "# Convert your data to PyTorch tensors, if not already in that format\n",
    "train_texts = torch.tensor(train_texts, dtype=torch.long)\n",
    "train_names = torch.tensor(train_names, dtype=torch.long)\n",
    "val_texts = torch.tensor(val_texts, dtype=torch.long)\n",
    "val_names = torch.tensor(val_names, dtype=torch.long)\n",
    "\n",
    "# Define the loss function and the optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Training parameters\n",
    "epochs = 30\n",
    "batch_size = 16\n",
    "\n",
    "# Create the DataLoader for training and validation data\n",
    "train_dataset = torch.utils.data.TensorDataset(train_texts, train_names)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = torch.utils.data.TensorDataset(val_texts, val_names)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "\n",
    "        # Reshape the labels for the loss function\n",
    "        labels = labels.view(-1)\n",
    "\n",
    "        outputs = outputs.view(-1, outputs.shape[-1])\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, labels) in enumerate(val_loader):\n",
    "            outputs = model(data)\n",
    "\n",
    "            # Reshape the labels for the loss function\n",
    "            labels = labels.view(-1)\n",
    "\n",
    "            outputs = outputs.view(-1, outputs.shape[-1])\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "    val_loss = running_loss / len(val_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss}, Val Loss: {val_loss}\")\n",
    "\n",
    "print(\"Training finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "024f67d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = model.fit(train_texts, train_names, epochs=30, batch_size=16, validation_data=(val_texts, val_names))\n",
    "#import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fddafb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert Keras model to PyTorch model\n",
    "#torch_model = torch.nn.Sequential(*[PyTorchWrapper(layer) for layer in model.layers])\n",
    "\n",
    "# Create a custom spaCy component\n",
    "class KerasEntityRecognizer(EntityRecognizer):\n",
    "    def predict(self, docs):\n",
    "        X = [doc.tensor for doc in docs]\n",
    "        X_padded = pad_sequences(X, maxlen=max_length, padding='post')\n",
    "        y_pred = self.model(torch.tensor(X_padded, dtype=torch.float32))\n",
    "        return y_pred.detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "017d548a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Language.component(\"keras_entity_recognizer\")\n",
    "def keras_entity_recognizer(doc):\n",
    "    # Convert the document text into input for the model\n",
    "    text_sequence = text_tokenizer.texts_to_sequences([doc.text])\n",
    "    text_sequence_padded = pad_sequences(text_sequence, maxlen=max_length, padding='post')\n",
    "\n",
    "    # Get the model predictions\n",
    "    predictions = model.predict(text_sequence_padded)[0]\n",
    "\n",
    "    # Extract the name from the predictions\n",
    "    name_indices = np.argmax(predictions, axis=-1)\n",
    "    name_tokens = [name_tokenizer.index_word[idx] if idx > 0 else '' for idx in name_indices]\n",
    "\n",
    "    # Assign the name tokens to the doc\n",
    "    for i, token in enumerate(doc):\n",
    "        if name_tokens[i]:\n",
    "            token._.name = name_tokens[i]\n",
    "        else:\n",
    "            token._.name = \"\"\n",
    "\n",
    "    # Add entities to the doc\n",
    "    for token in doc:\n",
    "        if token._.name:\n",
    "            doc.ents += (Span(doc, token.i, token.i + 1, label='PERSON'),)\n",
    "\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92ac6b98",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MyModel' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27680\\1050943502.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Process a text using the spaCy pipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\" Dr. Sharath Chandra Mouli is a medical doctor who specializes in the field of Gastroenterology. He is associated with the Krishna Institute of Medical Sciences (KIMS) Hospital in Secunderabad, Telangana, India.Dr. Mouli completed his MBBS degree from the Rajiv Gandhi University of Health Sciences in Bangalore, India, and then went on to pursue a Doctorate of Medicine (DM) in Gastroenterology from the Nizam's Institute of Medical Sciences in Hyderabad, India. He has several years of experience in the field of Gastroenterology and has worked at various prestigious institutions across India.Dr. Mouli's areas of expertise include the diagnosis and treatment of various gastrointestinal disorders such as inflammatory bowel disease, liver diseases, pancreatic disorders, and motility disorders. He is also trained in performing advanced endoscopic procedures such as endoscopic ultrasound (EUS), endoscopic retrograde cholangiopancreatography (ERCP), and endoscopic mucosal resection (EMR).Apart from his clinical work, Dr. Mouli is also involved in research activities in the field of Gastroenterology and has published several articles in peer-reviewed medical journals.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Print the extracted entities\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1014\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE109\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1016\u001b[1;33m                 \u001b[0merror_handler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1017\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1018\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE005\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturned_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mraise_error\u001b[1;34m(proc_name, proc, docs, e)\u001b[0m\n\u001b[0;32m   1687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1688\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mraise_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproc_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1689\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1009\u001b[0m                 \u001b[0merror_handler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_error_handler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1010\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1011\u001b[1;33m                 \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1012\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m                 \u001b[1;31m# This typically happens if a component is not initialized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27680\\2516158497.py\u001b[0m in \u001b[0;36mkeras_entity_recognizer\u001b[1;34m(doc)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# Get the model predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_sequence_padded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# Extract the name from the predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1267\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1268\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1269\u001b[1;33m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[0;32m   1270\u001b[0m             type(self).__name__, name))\n\u001b[0;32m   1271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MyModel' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "# Register the custom attribute\n",
    "Token.set_extension('name', default='')\n",
    "\n",
    "# Load a spaCy model and add the custom component\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe(\"keras_entity_recognizer\")\n",
    "\n",
    "# Process a text using the spaCy pipeline\n",
    "text = \" Dr. Sharath Chandra Mouli is a medical doctor who specializes in the field of Gastroenterology. He is associated with the Krishna Institute of Medical Sciences (KIMS) Hospital in Secunderabad, Telangana, India.Dr. Mouli completed his MBBS degree from the Rajiv Gandhi University of Health Sciences in Bangalore, India, and then went on to pursue a Doctorate of Medicine (DM) in Gastroenterology from the Nizam's Institute of Medical Sciences in Hyderabad, India. He has several years of experience in the field of Gastroenterology and has worked at various prestigious institutions across India.Dr. Mouli's areas of expertise include the diagnosis and treatment of various gastrointestinal disorders such as inflammatory bowel disease, liver diseases, pancreatic disorders, and motility disorders. He is also trained in performing advanced endoscopic procedures such as endoscopic ultrasound (EUS), endoscopic retrograde cholangiopancreatography (ERCP), and endoscopic mucosal resection (EMR).Apart from his clinical work, Dr. Mouli is also involved in research activities in the field of Gastroenterology and has published several articles in peer-reviewed medical journals.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "# Print the extracted entities\n",
    "print(\"Entities found:\", [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98de791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the named entities using displaCy\n",
    "#displacy.render(doc, style='ent', options={'ents': ['PERSON']})\n",
    "displacy.render(doc, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2521e993",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
